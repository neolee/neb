# Start Point

实现一个对 OCR 结果文本进行校对的智能体（*agent*）命令行工具。

1. 使用 `mal` 管理 LLM 配置，使用 `pydantic-ai` 作为构建 *agent* 的基本框架，使用 `logfire` 实现日志与审计；
2. 生成的代码全部置于 `ocr_proofreader.py` 文件中，代码结构及风格上尽量与本项目其他源代码保持一致（例如 `kb_local.py`）；
3. 程序通过命令行参数接受一个文件目录作为输入，目录内包含一组 Markdown 文件（`.md`），*agent* 应该逐一处理每个文件，以避免输入上下文过大的问题；只处理目录内的文件即可，不需要考虑子目录；可以一次处理一个文件，暂不考虑并行处理的问题；
4. 待审阅修订的文本可能包含两类错误：因为 OCR 误查引入的形近字错误，以及因为手工（拼音）输入导致的同音字错误，一般情况下不会出现大面积文本错误，但如果发现明显不通顺的词句也可以尝试修正；基于此设计清晰合理的提示词（*prompt*）；
5. 要求 LLM 针对每个目标 Markdown 文件中发现的问题，输出一个标准 GNU `diff` 格式的文本，以避免输出 token 过多的问题；
6. 基于 LLM 返回的 `diff` 文本对目标 Markdown 文件进行修改并保存；处理出现异常或错误无法完成时直接输出 LLM 返回的 `diff` 文本请用户手工处理；
7. 代码应结构清晰简洁，将不同功能模块划分为大小适中、高内聚、低耦合的函数，在有必要作出额外解释时给出简洁的注释，日志应该对调试及跟踪 token 用量有帮助。

# Iteration 1

经过测试，由于文本的特征，“使用 diff 格式来返回需要修改的文本”这个方案效果不是很好，请你设计一个 LLM 返回的数据格式，既能最大限度降低返回 token 量，又能方便地进行后续文本修改，并据此修改代码。
